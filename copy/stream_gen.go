// This file was automatically generated by genny.
// Any changes will be lost if this file is regenerated.
// see https://github.com/cheekybits/genny

package copy

// ByteArrayStringStream computes on a stream of key (ByteArray) value (String) messages.
type ByteArrayStringStream struct {
	app      *StreamingApplication
	ch       <-chan ByteArrayStringMsg
	commitCh <-chan interface{}
}

// ByteArrayStringMsg is a key value pair send through the computation graph.
type ByteArrayStringMsg struct {
	Key   ByteArray
	Value string
}

// Branch splits the stream into count new branches. Idx selects routes messages between the streams.
func (s ByteArrayStringStream) Branch(count int, idx func(m ByteArrayStringMsg) int) []ByteArrayStringStream {
	chs := make([]chan ByteArrayStringMsg, count)
	commitChs := make([]chan interface{}, count)
	streams := make([]ByteArrayStringStream, count)

	for i := 0; i < count; i++ {
		chs[i] = make(chan ByteArrayStringMsg, cap(s.ch))
		commitChs[i] = make(chan interface{}, 1)
		streams[i] = ByteArrayStringStream{
			ch:       chs[i],
			commitCh: commitChs[i],
		}
	}

	go func() {
		for {
			select {
			case msg := <-s.ch:
				chs[idx(msg)] <- msg

			case _, ok := <-s.commitCh:
				for len(s.ch) > 0 {
					msg := <-s.ch
					chs[idx(msg)] <- msg
				}

				for i := 0; i < count; i++ {
					commitChs[i] <- struct{}{}
				}

				if !ok {
					for i := 0; i < count; i++ {
						close(chs[i])
						close(commitChs[i])
					}
					return
				}
			}
		}
	}()

	return streams
}

// Filter keeps the messages with f(message) == True.
func (s ByteArrayStringStream) Filter(f func(m ByteArrayStringMsg) bool) ByteArrayStringStream {
	task := func(ch chan ByteArrayStringMsg, msg ByteArrayStringMsg) {
		if f(msg) {
			ch <- msg
		}
	}

	return s.Process(task)
}

// InverseFilter keeps the messages with f(message) == False.
func (s ByteArrayStringStream) InverseFilter(f func(m ByteArrayStringMsg) bool) ByteArrayStringStream {
	inverse := func(m ByteArrayStringMsg) bool {
		return !f(m)
	}
	return s.Filter(inverse)
}

// FlatMap creates 0-N messages per message.
func (s ByteArrayStringStream) FlatMap(f func(m ByteArrayStringMsg, e func(ByteArrayStringMsg))) ByteArrayStringStream {
	task := func(ch chan ByteArrayStringMsg, msg ByteArrayStringMsg) {
		e := func(m ByteArrayStringMsg) {
			ch <- m
		}

		f(msg, e)
	}

	return s.Process(task)
}

// FlatMapValues creates 0-N messages per message while keeping the key.
func (s ByteArrayStringStream) FlatMapValues(f func(v string, e func(v string))) ByteArrayStringStream {
	task := func(ch chan ByteArrayStringMsg, msg ByteArrayStringMsg) {
		e := func(v string) {
			m := ByteArrayStringMsg{
				Key:   msg.Key,
				Value: v,
			}
			ch <- m
		}

		f(msg.Value, e)
	}

	return s.Process(task)
}

// Foreach executes f per messages. The function is terminal and blocks until completion.
func (s ByteArrayStringStream) Foreach(f func(ByteArrayStringMsg)) {
	task := func(ch chan ByteArrayStringMsg, msg ByteArrayStringMsg) {
		f(msg)
	}

	stream := s.Process(task)

	go func() {
		s.app.requiredCommits++
		for range stream.commitCh {
			s.app.commits <- struct{}{}
		}
	}()
}

// Map uses m to compute a new message per message.
func (s ByteArrayStringStream) Map(m func(m ByteArrayStringMsg) ByteArrayStringMsg) ByteArrayStringStream {
	task := func(ch chan ByteArrayStringMsg, msg ByteArrayStringMsg) {
		ch <- m(msg)
	}

	return s.Process(task)
}

// MapValues uses m to compute new values for each message.
func (s ByteArrayStringStream) MapValues(m func(m string) string) ByteArrayStringStream {
	task := func(ch chan ByteArrayStringMsg, msg ByteArrayStringMsg) {
		msg.Value = m(msg.Value)
		ch <- msg
	}

	return s.Process(task)
}

// Merge combines multiple streams into one.
func (s ByteArrayStringStream) Merge(ss ...ByteArrayStringStream) ByteArrayStringStream {
	ch := make(chan ByteArrayStringMsg, cap(s.ch))
	commitCh := make(chan interface{}, 1)
	streamsCount := len(ss) + 1
	internalCommitCh := make(chan interface{}, streamsCount)
	stream := ByteArrayStringStream{
		ch:       ch,
		commitCh: commitCh,
	}
	wg := sync.WaitGroup{}

	copy := func(s ByteArrayStringStream) {
		for {
			select {
			case msg := <-s.ch:
				ch <- msg

			case _, ok := <-s.commitCh:
				for len(s.ch) > 0 {
					msg := <-s.ch
					ch <- msg
				}
				internalCommitCh <- struct{}{}

				if !ok {
					wg.Done()
					return
				}
			}
		}
	}

	wg.Add(1)
	go copy(s)
	for _, s := range ss {
		wg.Add(1)
		go copy(s)
	}

	go func() {
		wg.Wait()
		close(ch)
		close(commitCh)
		close(internalCommitCh)
	}()

	go func() {
		i := 0
		for range internalCommitCh {
			i := (i + 1) % streamsCount
			if i == 0 {
				commitCh <- struct{}{}
			}
		}
	}()

	return stream
}

// Peek executes p per message.
func (s ByteArrayStringStream) Peek(p func(ByteArrayStringMsg)) ByteArrayStringStream {
	task := func(ch chan ByteArrayStringMsg, msg ByteArrayStringMsg) {
		p(msg)
		ch <- msg
	}

	return s.Process(task)
}

// Print logs each message to the stderr.
func (s ByteArrayStringStream) Print() {
	s.Foreach(PrintByteArrayStringMsg)
}

// PrintByteArrayStringMsg prints a message to stderr.
func PrintByteArrayStringMsg(m ByteArrayStringMsg) {
	log.Printf("%v, %v\n", m.Key, m.Value)
}

// SelectKey creates a new key per message.
func (s ByteArrayStringStream) SelectKey(k func(m ByteArrayStringMsg) ByteArray) ByteArrayStringStream {
	task := func(ch chan ByteArrayStringMsg, msg ByteArrayStringMsg) {
		ch <- ByteArrayStringMsg{
			Key:   k(msg),
			Value: msg.Value,
		}
	}

	return s.Process(task)
}

// StreamByteArrayStringTopic subscribes to a topic and streams its messages.
func (s *StreamingApplication) StreamByteArrayStringTopic(topicName string, keyDecoder func(k []byte) (ByteArray, error), valueDecoder func(v []byte) (string, error)) ByteArrayStringStream {
	// TODO enforce only one read per topic, because only one offset is stored per stream.

	kafkaMsgCh := make(chan *kafka.Message, channelCap)
	commitCh := make(chan interface{}, 1)
	topic := topic{
		ch:       kafkaMsgCh,
		commitCh: commitCh,
	}
	s.subscriptions[topicName] = topic

	ch := make(chan ByteArrayStringMsg, channelCap)
	stream := ByteArrayStringStream{
		app:      s,
		ch:       ch,
		commitCh: commitCh,
	}

	convert := func(m *kafka.Message) ByteArrayStringMsg {
		key, err := keyDecoder(m.Key)
		if err != nil {
			log.Fatalf("decode key: key %v: %v", m.Key, err)
		}

		value, err := valueDecoder(m.Value)
		if err != nil {
			log.Fatalf("decode value: value %v: %v", m.Value, err)
		}

		return ByteArrayStringMsg{
			Key:   key,
			Value: value,
		}
	}

	go func() {
		for {
			select {
			case msg := <-kafkaMsgCh:
				ch <- convert(msg)

			case _, ok := <-commitCh:
				for len(kafkaMsgCh) > 0 {
					msg := <-kafkaMsgCh
					ch <- convert(msg)
				}
				commitCh <- struct{}{}

				if !ok {
					close(ch)
					close(commitCh)
					return
				}
			}
		}
	}()

	return stream
}

// WriteTo persists messages to a kafka topic.
func (s ByteArrayStringStream) WriteTo(topicName string, keyEncoder func(k ByteArray) ([]byte, error), valueEncoder func(v string) ([]byte, error)) *StreamingApplication {

	retries := 0
	task := func(m ByteArrayStringMsg) {
		key, err := keyEncoder(m.Key)
		if err != nil {
			log.Fatalf("encode key: key %v: %v", m.Key, err)
		}

		value, err := valueEncoder(m.Value)
		if err != nil {
			log.Fatalf("encode value: value %v: %v", m.Value, err)
		}

	produce:
		err = s.app.producer.Produce(&kafka.Message{
			TopicPartition: kafka.TopicPartition{
				Topic:     &topicName,
				Partition: kafka.PartitionAny,
			},
			Key:   key,
			Value: value,
		}, nil)
		if err != nil {
			ke := err.(kafka.Error)
			if ke.IsFatal() {
				log.Fatalf("fatal error: produce message: %v", err)
			}

			if ke.IsRetriable() {
				time.Sleep(10 * time.Millisecond)
				goto produce
			}

			if retries >= 20 {
				log.Fatalf("produce message: code %d: %v", ke.Code(), ke.Error())
			}

			time.Sleep(50 * time.Millisecond) // TODO: add exponential back off here
			retries++
			goto produce
		}

		retries = 0
	}

	go func() {
		s.app.requiredCommits++
		for {
			select {
			case msg := <-s.ch:
				task(msg)

			case <-s.commitCh:
				for len(s.ch) > 0 {
					msg := <-s.ch
					task(msg)
				}
				s.app.commits <- struct{}{}
			}
		}
	}()

	return s.app
}

// Repartition persists the stream into a topic and sorts the messages, based on their key, into partitions.
func (s ByteArrayStringStream) Repartition(
	topicName string,
	keyEncoder func(k ByteArray) ([]byte, error),
	valueEncoder func(v string) ([]byte, error),
	keyDecoder func(k []byte) (ByteArray, error),
	valueDecoder func(v []byte) (string, error),
) ByteArrayStringStream {
	return s.WriteTo(topicName, keyEncoder, valueEncoder).
		StreamByteArrayStringTopic(topicName, keyDecoder, valueDecoder)
}

// Process executes the task and creates a new stream.
func (s ByteArrayStringStream) Process(task func(ch chan ByteArrayStringMsg, m ByteArrayStringMsg)) ByteArrayStringStream {
	ch := make(chan ByteArrayStringMsg, cap(s.ch))
	commitCh := make(chan interface{}, 1)
	stream := ByteArrayStringStream{
		app:      s.app,
		ch:       ch,
		commitCh: commitCh,
	}

	go func() {
		for {
			select {
			case msg := <-s.ch:
				task(ch, msg)

			case _, ok := <-s.commitCh:
				for len(s.ch) > 0 {
					msg := <-s.ch
					task(ch, msg)
				}
				commitCh <- struct{}{}

				if !ok {
					close(ch)
					close(commitCh)
					return
				}
			}
		}
	}()

	return stream
}
