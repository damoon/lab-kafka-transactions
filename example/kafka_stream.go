// This file was automatically generated by genny.
// Any changes will be lost if this file is regenerated.
// see https://github.com/cheekybits/genny

package example

import (
	"log"
	"sync"
	"time"

	"github.com/confluentinc/confluent-kafka-go/kafka"
)

// KafkaKeyStringStream computes on a stream of key (KafkaKey) value (String) messages.
type KafkaKeyStringStream struct {
	app      *StreamingApplication
	ch       <-chan KafkaKeyStringMsg
	commitCh <-chan interface{}
}

// KafkaKeyStringMsg is a key value pair send through the computation graph.
type KafkaKeyStringMsg struct {
	Key   KafkaKey
	Value string
}

// Branch splits the stream into count new branches. Idx selects routes messages between the streams.
func (s KafkaKeyStringStream) Branch(count int, idx func(m KafkaKeyStringMsg) int) []KafkaKeyStringStream {
	chs := make([]chan KafkaKeyStringMsg, count)
	commitChs := make([]chan interface{}, count)
	streams := make([]KafkaKeyStringStream, count)

	for i := 0; i < count; i++ {
		chs[i] = make(chan KafkaKeyStringMsg, cap(s.ch))
		commitChs[i] = make(chan interface{}, 1)
		streams[i] = KafkaKeyStringStream{
			ch:       chs[i],
			commitCh: commitChs[i],
		}
	}

	go func() {
		for {
			select {
			case msg := <-s.ch:
				chs[idx(msg)] <- msg

			case _, ok := <-s.commitCh:
				for len(s.ch) > 0 {
					msg := <-s.ch
					chs[idx(msg)] <- msg
				}

				for i := 0; i < count; i++ {
					commitChs[i] <- struct{}{}
				}

				if !ok {
					for i := 0; i < count; i++ {
						close(chs[i])
						close(commitChs[i])
					}
					return
				}
			}
		}
	}()

	return streams
}

// Filter keeps the messages with f(message) == True.
func (s KafkaKeyStringStream) Filter(f func(m KafkaKeyStringMsg) bool) KafkaKeyStringStream {
	task := func(ch chan KafkaKeyStringMsg, msg KafkaKeyStringMsg) {
		if f(msg) {
			ch <- msg
		}
	}

	return s.Process(task)
}

// InverseFilter keeps the messages with f(message) == False.
func (s KafkaKeyStringStream) InverseFilter(f func(m KafkaKeyStringMsg) bool) KafkaKeyStringStream {
	inverse := func(m KafkaKeyStringMsg) bool {
		return !f(m)
	}
	return s.Filter(inverse)
}

// FlatMap creates 0-N messages per message.
func (s KafkaKeyStringStream) FlatMap(f func(m KafkaKeyStringMsg, e func(KafkaKeyStringMsg))) KafkaKeyStringStream {
	task := func(ch chan KafkaKeyStringMsg, msg KafkaKeyStringMsg) {
		e := func(m KafkaKeyStringMsg) {
			ch <- m
		}

		f(msg, e)
	}

	return s.Process(task)
}

// FlatMapValues creates 0-N messages per message while keeping the key.
func (s KafkaKeyStringStream) FlatMapValues(f func(v string, e func(v string))) KafkaKeyStringStream {
	task := func(ch chan KafkaKeyStringMsg, msg KafkaKeyStringMsg) {
		e := func(v string) {
			m := KafkaKeyStringMsg{
				Key:   msg.Key,
				Value: v,
			}
			ch <- m
		}

		f(msg.Value, e)
	}

	return s.Process(task)
}

// Foreach executes f per messages. The function is terminal and blocks until completion.
func (s KafkaKeyStringStream) Foreach(f func(KafkaKeyStringMsg)) {
	task := func(ch chan KafkaKeyStringMsg, msg KafkaKeyStringMsg) {
		f(msg)
	}

	stream := s.Process(task)

	for range stream.commitCh {
	}
}

// Map uses m to compute a new message per message.
func (s KafkaKeyStringStream) Map(m func(m KafkaKeyStringMsg) KafkaKeyStringMsg) KafkaKeyStringStream {
	task := func(ch chan KafkaKeyStringMsg, msg KafkaKeyStringMsg) {
		ch <- m(msg)
	}

	return s.Process(task)
}

// MapValues uses m to compute new values for each message.
func (s KafkaKeyStringStream) MapValues(m func(m string) string) KafkaKeyStringStream {
	task := func(ch chan KafkaKeyStringMsg, msg KafkaKeyStringMsg) {
		msg.Value = m(msg.Value)
		ch <- msg
	}

	return s.Process(task)
}

// Merge combines multiple streams into one.
func (s KafkaKeyStringStream) Merge(ss ...KafkaKeyStringStream) KafkaKeyStringStream {
	ch := make(chan KafkaKeyStringMsg, cap(s.ch))
	commitCh := make(chan interface{}, 1)
	streamsCount := len(ss) + 1
	internalCommitCh := make(chan interface{}, streamsCount)
	stream := KafkaKeyStringStream{
		ch:       ch,
		commitCh: commitCh,
	}
	wg := sync.WaitGroup{}

	copy := func(s KafkaKeyStringStream) {
		for {
			select {
			case msg := <-s.ch:
				ch <- msg

			case _, ok := <-s.commitCh:
				for len(s.ch) > 0 {
					msg := <-s.ch
					ch <- msg
				}
				internalCommitCh <- struct{}{}

				if !ok {
					wg.Done()
					return
				}
			}
		}
	}

	wg.Add(1)
	go copy(s)
	for _, s := range ss {
		wg.Add(1)
		go copy(s)
	}

	go func() {
		wg.Wait()
		close(ch)
		close(commitCh)
		close(internalCommitCh)
	}()

	go func() {
		i := 0
		for range internalCommitCh {
			i := (i + 1) % streamsCount
			if i == 0 {
				commitCh <- struct{}{}
			}
		}
	}()

	return stream
}

// Peek executes p per message.
func (s KafkaKeyStringStream) Peek(p func(KafkaKeyStringMsg)) KafkaKeyStringStream {
	task := func(ch chan KafkaKeyStringMsg, msg KafkaKeyStringMsg) {
		p(msg)
		ch <- msg
	}

	return s.Process(task)
}

// Print logs each message to the stderr.
func (s KafkaKeyStringStream) Print() {
	s.Foreach(PrintKafkaKeyStringMsg)
}

// PrintKafkaKeyStringMsg prints a message to stderr.
func PrintKafkaKeyStringMsg(m KafkaKeyStringMsg) {
	log.Printf("%v, %v\n", m.Key, m.Value)
}

// SelectKey creates a new key per message.
func (s KafkaKeyStringStream) SelectKey(k func(m KafkaKeyStringMsg) KafkaKey) KafkaKeyStringStream {
	task := func(ch chan KafkaKeyStringMsg, msg KafkaKeyStringMsg) {
		ch <- KafkaKeyStringMsg{
			Key:   k(msg),
			Value: msg.Value,
		}
	}

	return s.Process(task)
}

// StreamKafkaKeyStringTopic subscribes to a topic and streams its messages.
func (s *StreamingApplication) StreamKafkaKeyStringTopic(topicName string, keyDecoder func(k []byte) KafkaKey, valueDecoder func(v []byte) string) KafkaKeyStringStream {
	kafkaMsgCh := make(chan kafka.Message, channelCap)
	commitCh := make(chan interface{}, 1)
	topic := topic{
		ch:       kafkaMsgCh,
		commitCh: commitCh,
	}
	s.subscriptions[topicName] = topic

	ch := make(chan KafkaKeyStringMsg, channelCap)
	stream := KafkaKeyStringStream{
		app:      s,
		ch:       ch,
		commitCh: commitCh,
	}

	convert := func(m kafka.Message) KafkaKeyStringMsg {
		return KafkaKeyStringMsg{
			Key:   keyDecoder(m.Key),
			Value: valueDecoder(m.Value),
		}
	}

	go func() {
		for {
			select {
			case msg := <-kafkaMsgCh:
				ch <- convert(msg)

			case _, ok := <-commitCh:
				for len(kafkaMsgCh) > 0 {
					msg := <-kafkaMsgCh
					ch <- convert(msg)
				}
				commitCh <- struct{}{}

				if !ok {
					close(ch)
					close(commitCh)
					return
				}
			}
		}
	}()

	return stream
}

// WriteTo persists messages to a kafka topic.
func (s KafkaKeyStringStream) WriteTo(topicName string, keyDecoder func(k KafkaKey) []byte, valueDecoder func(v string) []byte) *StreamingApplication {

	task := func(m KafkaKeyStringMsg) {
	produce:
		err := s.app.producer.Produce(&kafka.Message{
			TopicPartition: kafka.TopicPartition{
				Topic:     &topicName,
				Partition: kafka.PartitionAny,
			},
			Key:   keyDecoder(m.Key),
			Value: valueDecoder(m.Value),
		}, nil)
		if err != nil {
			if err.(kafka.Error).IsFatal() {
				log.Fatalf("fatal error: produce message: %v", err)
			}

			log.Printf("produce message: %v", err)
			time.Sleep(10 * time.Millisecond)
			goto produce
		}
	}

	go func() {
		for {
			select {
			case msg := <-s.ch:
				task(msg)

			case <-s.commitCh:
				for len(s.ch) > 0 {
					msg := <-s.ch
					task(msg)
				}
				s.app.commits <- struct{}{}
			}
		}
	}()

	return s.app
}

// Process executes the task and creates a new stream.
func (s KafkaKeyStringStream) Process(task func(ch chan KafkaKeyStringMsg, m KafkaKeyStringMsg)) KafkaKeyStringStream {
	ch := make(chan KafkaKeyStringMsg, cap(s.ch))
	commitCh := make(chan interface{}, 1)
	stream := KafkaKeyStringStream{
		app:      s.app,
		ch:       ch,
		commitCh: commitCh,
	}

	go func() {
		for {
			select {
			case msg := <-s.ch:
				task(ch, msg)

			case _, ok := <-s.commitCh:
				for len(s.ch) > 0 {
					msg := <-s.ch
					task(ch, msg)
				}
				commitCh <- struct{}{}

				if !ok {
					close(ch)
					close(commitCh)
					return
				}
			}
		}
	}()

	return stream
}
